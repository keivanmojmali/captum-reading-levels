{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43654f73-5380-4341-828b-b05a363449bb",
   "metadata": {},
   "source": [
    "# Figuring out which features are the most important for classifying reading levels with LLaMA-3\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "In this project, we will utilize the LLaMA-3 model to classify various text passages according to their reading levels. Our primary objective is to not only get the reading level predictions but also to understand the underlying reasons behind these predictions. To achieve this, we will employ the Captum library, which is designed for model interpretability, to identify and analyze the features that are most influential in the model's decision-making process.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "- **Prediction**: Use the LLaMA-3 model to determine the reading levels of various text passages.\n",
    "- **Interpretability**: Implement Captum to dissect the model's predictions and pinpoint the key features that contribute to the determined reading levels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e0b6c9a-e177-46bb-850f-cd51be722ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import transformers\n",
    "import captum\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from captum.attr import IntegratedGradients\n",
    "\n",
    "\n",
    "HUGGING_FACE_TOKEN=\"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\"\n",
    "\n",
    "client = boto3.client(\n",
    "    \"bedrock-runtime\",\n",
    "    region_name=\"us-east-1\",\n",
    "    aws_access_key_id=\"AKIAZQ3DTFQUG54IITUW\",\n",
    "    aws_secret_access_key=\"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\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84a1ce0f-1035-4c46-8a73-6d4beea5a4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llama3_call(size, messages):\n",
    "    \n",
    "    # models from aws bedrock\n",
    "    model = {\n",
    "        \"8b\": \"meta.llama3-8b-instruct-v1:0\",\n",
    "        \"70b\": \"meta.llama3-12b-v1:0\",\n",
    "    }\n",
    "\n",
    "    # tokenizers from huggingface\n",
    "    model_tokenizer = {\n",
    "        \"8b\": \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "        \"70b\": \"meta-llama/Meta-Llama-3-70B-Instruct\",\n",
    "    }\n",
    "\n",
    "    # Set the model ID, e.g., Llama 3 8B Instruct.\n",
    "    model_id = model[size]\n",
    "\n",
    "    # load the tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_tokenizer[size], token=HUGGING_FACE_TOKEN\n",
    "    )\n",
    "\n",
    "    # Apply the chat template to the messages.\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    # Format the request payload using the model's native structure.\n",
    "    request = {\n",
    "        \"prompt\": prompt,\n",
    "        # Optional inference parameters:\n",
    "        \"max_gen_len\": 500,\n",
    "        \"temperature\": 0.7,\n",
    "        \"top_p\": 0.9,\n",
    "    }\n",
    "\n",
    "    # Encode and send the request.\n",
    "    response = client.invoke_model(\n",
    "        body=json.dumps(request),\n",
    "        modelId=model_id,\n",
    "    )\n",
    "\n",
    "    response_body = json.loads(response.get(\"body\").read())\n",
    "    content = response_body.get(\"generation\")\n",
    "\n",
    "    return content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42e55d65-8784-4386-b962-7400a7919aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keivan/Desktop/ml-repos/captum-reading-levels/env/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the passage, I would classify the reading level as approximately 9th-10th grade (around 14-15 years old). The vocabulary, syntax, and tone of the passage are all consistent with a high school student's writing style.\n",
      "\n",
      "The passage uses a range of vocabulary, including words like \"bougie,\" \"Nae-Nae,\" \"slayed,\" \"condoms,\" and \"trump card,\" which may be unfamiliar to younger readers. The syntax is also complex, with long sentences and multiple clauses, which may challenge younger readers.\n",
      "\n",
      "The tone of the passage is conversational and informal, which is consistent with a high school student's writing style. The narrator uses colloquial language and slang, which adds to the informal tone.\n",
      "\n",
      "Overall, the passage is written in a style that is typical of high school students, and it would likely be challenging for younger readers to understand without assistance.\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"You are an expert in classifying the reading levels of passages. You read the passages and then assign the grade level that matches the reading level of the passages most closely.\"\n",
    "\n",
    "final_prompt = \"Classify the reading level of the following passage: I shouldn't have come to this party. I'm not even sure I belong at this party. That's not on some bougie shit, either. There are just some places where it's not enough to be me. Neither version of me. Big D's spring break party is one of those places. I squeeze through sweaty bodies and follow Kenya, her curls bouncing past her shoulders. A haze lingers over the room, smelling like weed, and music rattles the floor. Some rapper calls out for everybody to Nae-Nae, followed by a bunch of 'Heys' as people launch into their own versions. Kenya holds up her cup and dances her way through the crowd. Between the headache from the loud-ass music and the nausea from the weed odor, I'll be amazed if I cross the room without spilling my drink. We break out the crowd. Big D's house is packed wall-to-wall. I've always heard that everybody and their momma comes to his spring break parties—well, everybody except me—but damn, I didn't know it would be this many people. Girls wear their hair colored, curled, laid, and slayed. Got me feeling basic as hell with my ponytail. Guys in their freshest kicks and sagging pants grind so close to girls they just about need condoms. My nana likes to say that spring brings love. Spring in Garden Heights doesn't always bring love, but it promises babies in the winter. I wouldn't be surprised if a lot of them are conceived the night of Big D's party. He always has it on the Friday of spring break because you need Saturday to recover and Sunday to repent. Stop following me and go dance, Starr, Kenya says. People already say you think you all that. I didn't know so many mind readers lived in Garden Heights. Or that people know me as anything other than Big Mav's daughter who works in the store. I sip my drink and spit it back out. I knew there would be more than Hawaiian Punch in it, but this is way stronger than I'm used to. They shouldn't even call it punch. Just straight-up liquor. I put it on the coffee table and say, Folks kill me, thinking they know what I think. Hey, I'm just saying. You act like you don't know nobody 'cause you go to that school. I've been hearing that for six years, ever since my parents put me in Williamson Prep. Whatever, I mumble. And it wouldn't kill you to not dress like . . . She turns up her nose as she looks from my sneakers to my oversized hoodie. That. Ain't that my brother's hoodie? Our brother's hoodie. Kenya and I share an older brother, Seven. But she and I aren't related. Her momma is Seven's momma, and my dad is Seven's dad. Crazy, I know. Yeah, it's his. Figures. You know what else people saying too. Got folks thinking you're my girlfriend. Do I look like I care what people think? No! And that's the problem! Whatever. If I knew following her to this party meant she'd be on some Extreme Makeover: Starr Edition mess, I would've stayed home and watched The Fresh Prince reruns. My Jordans are comfortable, and damn, they're new. That's more than some people can say. The hoodie's way too big, but I like it that way. Plus, if I pull it over my nose, I can't smell the weed. Well, I ain't babysitting you all night, so you better do something, Kenya says and scopes the room. Kenya could be a model, if I'm completely honest. She's got flawless dark-brown skin—I don't think she ever gets a pimple—slanted brown eyes, and long eyelashes that aren't store-bought. She's the perfect height for modeling too, but a little thicker than those toothpicks on the runway. She never wears the same outfit twice. Her daddy, King, makes sure of that. Kenya is about the only person I hang out with in Garden Heights—it's hard to make friends when you go to a school that's forty-five minutes away and you're a latchkey kid who's only seen at her family's store. It's easy to hang out with Kenya because of our connection to Seven. She's messy as hell sometimes, though. Always fighting somebody and quick to say her daddy will whoop somebody's ass. Yeah it's true, but I wish she'd stop picking fights so she can use her trump card. Hell, I could use mine too. Everybody knows you don't mess with my dad, Big Mav, and you definitely don't mess with his kids. Still, you don't see me going around starting shit. Like at Big D's party, Kenya is giving Denasia Allen some serious stank eye. I don't remember much about Denasia, but I remember that she and Kenya haven't liked each other since fourth grade. Tonight, Denasia's dancing with some guy halfway across the room and paying no attention to Kenya. But no matter where we move, Kenya spots Denasia and glares at her. And the thing about the stank eye is at some point you feel it on you, inviting you to kick some ass or have your ass kicked. Ooh! I can't stand her, Kenya seethes. The other day, we were in line in the cafeteria, right? And she behind me, talking out the side of her neck. She didn't use my name, but I know she was talking 'bout me, saying I tried to get with DeVante.\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": final_prompt},\n",
    "]\n",
    "\n",
    "reading_level_prediciton = llama3_call('8b',messages)\n",
    "\n",
    "print(reading_level_prediciton)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "324b9112-bdde-4cd9-83fe-3ae8abd1cb58",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Initialize Integrated Gradients\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m ig \u001b[38;5;241m=\u001b[39m IntegratedGradients(model)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Compute attributions using Integrated Gradients\u001b[39;00m\n\u001b[1;32m      5\u001b[0m attributions, delta \u001b[38;5;241m=\u001b[39m ig\u001b[38;5;241m.\u001b[39mattribute(inputs\u001b[38;5;241m=\u001b[39minput_ids, target\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, return_convergence_delta\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model_name = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Initialize Integrated Gradients\n",
    "ig = IntegratedGradients(model)\n",
    "\n",
    "# Compute attributions using Integrated Gradients\n",
    "attributions, delta = ig.attribute(inputs=input_ids, target=1, return_convergence_delta=True)\n",
    "attributions = attributions.sum(dim=-1).squeeze(0)  # Summing across all embedding dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e88cbe8b-c2dc-4abb-a771-3d5d91b1eb20",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tokens \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mconvert_ids_to_tokens(inputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m20\u001b[39m,\u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(attributions\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mro-\u001b[39m\u001b[38;5;124m'\u001b[39m, linewidth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, markersize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(attributions.detach().numpy(), 'ro-', linewidth=2, markersize=5)\n",
    "plt.xticks(list(range(len(tokens))), tokens, rotation=\"vertical\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00abb2f8-c98a-438f-a4dd-337ef664cf96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
